# üß± Proyecto Integrador ‚Äì Fase 1

Este repositorio corresponde al **Avance 1** del Proyecto Integrador de Henry, enfocado en la construcci√≥n de un sistema de an√°lisis de ventas para una empresa distribuida geogr√°ficamente. El objetivo es aplicar conceptos de bases de datos, programaci√≥n orientada a objetos (POO), pruebas unitarias y buenas pr√°cticas de ingenier√≠a de datos.

---

## ‚úÖ Objetivos de esta fase

- Estructurar el proyecto con buenas pr√°cticas.
- Modelar las entidades del negocio como clases en Python.
- Cargar datos desde archivos `.csv` a una base de datos PostgreSQL.
- Validar los datos cargados.
- Implementar pruebas unitarias simples con `pytest`.

---

## üóÇÔ∏è Estructura del Proyecto

```
proyecto_integrador/
‚îú‚îÄ‚îÄ data/                     # Archivos CSV de entrada
‚îú‚îÄ‚îÄ src/                      # C√≥digo fuente del modelo de datos
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Define src como m√≥dulo de Python
‚îÇ   ‚îî‚îÄ‚îÄ models.py             # Clases que representan las tablas (POO)
‚îú‚îÄ‚îÄ sql/                      # Scripts SQL de creaci√≥n y carga de datos
‚îÇ   ‚îî‚îÄ‚îÄ load_data.sql
‚îú‚îÄ‚îÄ tests/                    # Pruebas unitarias
‚îÇ   ‚îî‚îÄ‚îÄ test_models.py
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                 # Este archivo
‚îî‚îÄ‚îÄ .env                      # Variables de entorno (no incluido en git)

---

## ‚ñ∂Ô∏è C√≥mo correr el proyecto localmente

1. **Clonar el repositorio**:

```bash
git clone <repo-url>
cd proyecto_integrador
```
2. **Crear y activar entorno virtual**:

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```
3. **Instalar dependencias**:

```bash
pip install -r requirements.txt
```
4. **Verificar que la carpeta `src/` tenga un archivo `__init__.py`**:

```bash
touch src/__init__.py  # o crear manualmente un archivo vac√≠o
```
5. **Configuraci√≥n de la Base de Datos**:

Se utiliz√≥ **PostgreSQL en un contenedor Docker**:

```bash
docker run --name pg-integrador -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=admin123 -e POSTGRES_DB=proyecto_integrador -p 5432:5432 -d postgres:15
```

Los archivos `.csv` fueron copiados al contenedor:

```bash
docker cp ./data/. pg-integrador:/data
```
---

## üß± Script de Creaci√≥n y Carga

**Ejecutar script SQL en DBeaver o desde psql**:

El script SQL completo se encuentra en [`sql/load_data.sql`](sql/load_data.sql), e incluye:

- `CREATE TABLE` para cada entidad: `countries`, `cities`, `customers`, `employees`, `sales`, `products`, `categories`.
- `COPY` para cargar los `.csv`.

---

## üîÑ Validaci√≥n de Carga

Se validaron las filas cargadas en cada tabla:

| Tabla       | Registros |
|-------------|-----------|
| countries   | 206       |
| cities      | 96        |
| categories  | 11        |
| products    | 452       |
| customers   | 98759     |
| employees   | 23        |
| sales       | 50000     |

Tambi√©n se corrigieron errores de formato en campos como `ModifyDate` y `SalesDate`.

---

6. **Correr los tests**:

Se implementaron dos pruebas b√°sicas usando `pytest` en el archivo `tests/test_models.py`:

- Creaci√≥n de objeto `Product`
- M√©todo personalizado `full_name` en `Customer`

Para correr los tests:

```bash
pytest tests/test_models.py -v
```
---

## ‚úîÔ∏è Estado de Avance

| Requisito                            | Cumplido |
|--------------------------------------|-----------|
| Estructura del proyecto              | ‚úÖ       |
| Carga de datos en base PostgreSQL    | ‚úÖ       |
| Clases Python con POO                | ‚úÖ       |
| Pruebas con pytest                   | ‚úÖ       |
| Validaci√≥n de datos                  | ‚úÖ       |
| Documentaci√≥n (README)               | ‚úÖ       |

---
## ‚úÖ Requisitos cumplidos

### 1. Creaci√≥n de la base de datos y carga de CSV
- Se cre√≥ una instancia de PostgreSQL en Docker.
- Se generaron las tablas `countries`, `cities`, `customers`, `employees`, `products`, `sales` y `categories` a partir del modelo l√≥gico.
- Se cargaron datos desde los CSV usando sentencias `COPY` dentro del contenedor.

### 2. Normalizaci√≥n
- Se reemplazaron los campos `CityName` y `CountryName` por `CityID` y `CountryID` en la tabla `customers`.
- Se resolvieron los valores `NULL` en `CountryID` con una sentencia `UPDATE` basada en join entre `customers`, `cities` y `countries`.

### 3. Programaci√≥n orientada a objetos
- Se model√≥ cada entidad como clase Python en `src/models.py`, aplicando encapsulamiento, m√©todos auxiliares (`full_name`) y `__repr__` para facilitar depuraci√≥n.
- Las clases modeladas fueron: `Category`, `Country`, `City`, `Customer`, `Employee`, `Product` y `Sale`.

### 4. Pruebas unitarias
- Se implementaron pruebas en `tests/test_models.py` para validar el comportamiento de instanciaci√≥n y m√©todos personalizados como `full_name`.
- Se us√≥ `pytest`, permitiendo detecci√≥n autom√°tica de tests.

---
## üìå Notas finales

- Se manejaron correctamente tipos de datos y relaciones con claves for√°neas.
- Se corrigieron valores inv√°lidos manualmente (`SalesDate`, `ModifyDate`).
- Se establecieron convenciones de nombres y estilos para facilitar futuras ampliaciones del sistema.
- En la tabla `products`, el campo `ModifyDate` se almacena como `TEXT` por problemas de formato en los datos.
- En la tabla `sales`, el campo `SalesDate` tambi√©n se almacena como `TEXT`, ya que los valores no respetan un formato de fecha v√°lido (`31:24.2`).
- La integridad referencial fue respetada con claves for√°neas (`FOREIGN KEY`) entre tablas relacionadas.
- Los datos cargados desde los `.csv` fueron verificados en cuanto a cantidad de registros y consistencia.

---

# üß± Proyecto Integrador ‚Äì Fase 2 ‚Äì Modularizaci√≥n, patrones de dise√±o y consultas en Python

Esta etapa aborda la modularizaci√≥n del sistema, la aplicaci√≥n de patrones de dise√±o, la conexi√≥n entre Python y MySQL, y la ejecuci√≥n de consultas SQL desde c√≥digo, junto con pruebas unitarias y protecci√≥n de credenciales.

## ‚úÖ Objetivos de esta fase

- Modularizar el proyecto utilizando patrones de dise√±o.
- Crear una clase de conexi√≥n a la base de datos aplicando el patr√≥n Singleton.
- Ejecutar consultas SQL desde Python y devolver resultados como pandas.DataFrame.
- Aplicar buenas pr√°cticas de desacoplamiento, encapsulamiento y separaci√≥n de responsabilidades.
- Proteger credenciales con python-dotenv.
- Integrar todo en un Jupyter Notebook de presentaci√≥n.
- Agregar pruebas unitarias enfocadas en la nueva l√≥gica.

## üìÅ Estructura del Proyecto

proyecto_integrador/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îî‚îÄ‚îÄ repository.py
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ load_data.sql
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_database.py
‚îÇ   ‚îî‚îÄ‚îÄ test_repository.py
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_analisis_exploratorio.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 2_analisis_de_ventas.ipynb
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

## ‚öôÔ∏è Configuraci√≥n del entorno

1. Crear entorno virtual:
    python -m venv venv
    source venv/bin/activate (o venv\Scripts\activate en Windows)

2. Instalar dependencias:
    pip install -r requirements.txt

3. Archivo `.env`:

    DB_USER=root
    DB_PASSWORD=tu_password
    DB_HOST=localhost
    DB_PORT=3306
    DB_NAME=proyecto_integrador

4. `.gitignore` debe incluir:

    .env

## üß† Patr√≥n Singleton aplicado

Clase DBConnection:

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

class DBConnection:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            load_dotenv()
            user = os.getenv("DB_USER")
            password = os.getenv("DB_PASSWORD")
            host = os.getenv("DB_HOST")
            port = os.getenv("DB_PORT")
            db = os.getenv("DB_NAME")

            cls._instance = super().__new__(cls)
            url = f"mysql+pymysql://{user}:{password}@{host}:{port}/{db}"
            cls._instance.engine = create_engine(url)
            cls._instance.Session = sessionmaker(bind=cls._instance.engine)
        return cls._instance

    def get_session(self):
        return self.Session()

## üîç Consulta SQL desde Python

import pandas as pd
from src.db.database import DBConnection

def get_top_products(limit=10):
    session = DBConnection().get_session()
    query = f'''
        SELECT p.ProductName, SUM(s.Quantity) AS TotalSold
        FROM sales s
        JOIN products p ON s.ProductID = p.ProductID
        GROUP BY p.ProductName
        ORDER BY TotalSold DESC
        LIMIT {limit};
    '''
    df = pd.read_sql(query, session.bind)
    session.close()
    return df

## üß™ Test Unitario

from src.db.database import DBConnection

def test_singleton_instance():
    db1 = DBConnection()
    db2 = DBConnection()
    assert db1 is db2

## üìì Notebook de integraci√≥n

Incluye:

- Verificaci√≥n de conexi√≥n
- Ejecuci√≥n de consultas
- Resultados visualizados
- Justificaci√≥n de patrones
- Prueba unitaria visible

## ‚úÖ Requisitos cumplidos

| Requisito                                           | Estado |
|-----------------------------------------------------|--------|
| Patr√≥n Singleton implementado                       | ‚úÖ     |
| Clase de conexi√≥n con SQLAlchemy                    | ‚úÖ     |
| Consulta SQL con pandas                             | ‚úÖ     |
| Variables de entorno con dotenv                     | ‚úÖ     |
| .env ignorado por Git                               | ‚úÖ     |
| Test unitario del patr√≥n                            | ‚úÖ     |
| Notebook completo con resultados visibles           | ‚úÖ     |

# üß± Proyecto Integrador ‚Äì Fase 3: SQL Avanzado y Optimizaci√≥n

Este documento detalla los avances correspondientes a la **Fase 3 y final** del Proyecto Integrador. El objetivo de esta etapa fue refinar el sistema, moviendo la l√≥gica de an√°lisis compleja desde la aplicaci√≥n Python hacia la base de datos PostgreSQL.

El principio rector de esta fase fue **"mover el c√≥mputo a los datos, no los datos al c√≥mputo"**. Se implementaron t√©cnicas avanzadas de SQL para mejorar el rendimiento, la mantenibilidad y la eficiencia general del sistema de an√°lisis.

---

## ‚úÖ Objetivos de esta Fase

- **Crear y ejecutar consultas SQL avanzadas** utilizando **CTEs (Common Table Expressions)** y **Funciones de Ventana** (`ROW_NUMBER()`, `LAG()`).
- **Dise√±ar y crear al menos dos objetos programables en SQL** para encapsular l√≥gica y simplificar el acceso a los datos. Se eligieron una **Vista** y un **Procedimiento Almacenado** por su alto impacto en la arquitectura.
- **Integrar la ejecuci√≥n** de estas consultas y objetos desde la capa de datos de Python (`DataRepository`).
- **Documentar y presentar los resultados** en el Jupyter Notebook final, explicando las t√©cnicas utilizadas y los insights obtenidos.
- **Actualizar la documentaci√≥n final** del proyecto (`README.md`) para reflejar una arquitectura completa y profesional.

---

## üèõÔ∏è Arquitectura y Decisiones de Ingenier√≠a (Fase 3)

En esta fase, no se modific√≥ la arquitectura de tres capas existente, sino que se **enriqueci√≥ la capa de datos (PostgreSQL)**, d√°ndole m√°s responsabilidades de an√°lisis para que la aplicaci√≥n Python pudiera ser m√°s ligera y declarativa.

### 1. Consultas Anal√≠ticas Avanzadas

Para responder preguntas de negocio complejas, se implementaron dos consultas anal√≠ticas directamente en el `DataRepository`.

- **Ranking de Productos por Categor√≠a:**
  - **Problema:** Identificar los productos "estrella" dentro de cada categor√≠a. Un simple `GROUP BY` es insuficiente.
  - **Soluci√≥n:** Se utiliz√≥ una **CTE** para pre-calcular las ventas por producto y luego la funci√≥n de ventana **`ROW_NUMBER() OVER (PARTITION BY ...)`** para asignar un ranking a cada producto *dentro* de su categor√≠a. Esto permite un filtrado trivial de los "Top N" productos.
  - **Beneficio:** El c√°lculo se realiza enteramente en la base de datos de forma muy eficiente, y Python solo recibe el resultado final ya procesado.

- **An√°lisis de Crecimiento Mensual:**
  - **Problema:** Calcular la tasa de crecimiento de ingresos mes a mes. Esto requiere comparar la fila de un mes con la del mes anterior.
  - **Soluci√≥n:** Se us√≥ la funci√≥n de ventana **`LAG()`** para acceder a los ingresos del mes anterior en la misma fila del mes actual, permitiendo el c√°lculo del crecimiento porcentual directamente en la sentencia `SELECT`.
  - **Beneficio:** Evita la necesidad de traer toda la serie temporal a Pandas para luego hacer un `shift()` y calcular la diferencia, lo cual ser√≠a mucho menos performante.

### 2. Vista para Simplificaci√≥n de Datos (`v_ventas_detalladas`)

- **Problema:** Las consultas de an√°lisis a menudo requer√≠an unir 5 o 6 tablas (`sales`, `customers`, `products`, `cities`, etc.), lo que resultaba en c√≥digo SQL repetitivo, propenso a errores y dif√≠cil de mantener.
- **Soluci√≥n:** Se cre√≥ una **VISTA** llamada `v_ventas_detalladas`. Una vista es una tabla virtual almacenada como una consulta `SELECT`. Esta vista contiene todos los `JOINs` pre-configurados.
- **Beneficio:** Ahora, en lugar de escribir `JOINs` complejos, cualquier consulta puede simplemente hacer un `SELECT` a esta vista como si fuera una tabla normal. Esto **abstrae la complejidad**, reduce errores y asegura consistencia en el acceso a los datos.

### 3. Procedimiento Almacenado para L√≥gica de Negocio (`sp_reporte_cliente`)

- **Problema:** Ciertas operaciones, como generar un reporte completo para un cliente espec√≠fico, son una l√≥gica de negocio com√∫n que se quiere reutilizar y que requiere un par√°metro de entrada.
- **Soluci√≥n:** Se cre√≥ un **PROCEDIMIENTO ALMACENADO** (implementado como una `FUNCTION` en PostgreSQL) que acepta un `CustomerID` como par√°metro. Toda la l√≥gica para calcular el total gastado, la categor√≠a favorita y otros KPIs del cliente est√° encapsulada dentro de este procedimiento en el servidor.
- **Beneficio:**
  - **Rendimiento:** Reduce el tr√°fico de red, ya que la aplicaci√≥n solo env√≠a un ID y recibe un peque√±o resultado final.
  - **Mantenibilidad:** La l√≥gica de negocio del "reporte de cliente" est√° en un solo lugar. Si necesita cambiar, se modifica el procedimiento sin tocar la aplicaci√≥n Python.
  - **Seguridad:** Limita el tipo de operaciones que la aplicaci√≥n puede realizar, exponiendo solo la funcionalidad deseada.

---

## üìå Desaf√≠o Clave: Calidad de Datos de Origen

- **El Problema:** Durante la implementaci√≥n, se confirm√≥ que la columna `sales.SalesDate` conten√≠a datos de texto inv√°lidos (ej. `"31:24.2"`) que imped√≠an su tratamiento como un tipo `TIMESTAMP` nativo.
- **La Soluci√≥n (Mitigaci√≥n en la Vista):** Para solucionar esto sin alterar los datos crudos, se implement√≥ una expresi√≥n `CASE WHEN ...` dentro de la `CREATE VIEW`. Esta l√≥gica utiliza una expresi√≥n regular para validar el formato de la fecha en cada fila. Si el formato es v√°lido, lo convierte a `TIMESTAMP`; si es inv√°lido, lo convierte a `NULL`, evitando as√≠ que las consultas fallen.
- **Propuesta de Mejora (Est√°ndar Industrial):** La soluci√≥n definitiva y m√°s robusta ser√≠a implementar un **script de ETL previo a la carga**. Este script, escrito en Python con Pandas, se encargar√≠a de leer el CSV, limpiar y estandarizar la columna de fecha (`pd.to_datetime(..., errors='coerce')`), y guardar un `sales_cleaned.csv`. El proceso de carga en SQL se har√≠a entonces desde este archivo limpio, permitiendo que la columna en la base de datos sea de tipo `TIMESTAMP` nativo, lo que garantizar√≠a la m√°xima integridad y rendimiento.

---

## ‚ñ∂Ô∏è C√≥mo Verificar el Avance 3

1. **Ejecutar los Objetos SQL:** En un cliente SQL, ejecutar el script `sql/3_advanced_objects.sql` para crear la Vista y el Procedimiento Almacenado.
2. **Ejecutar el Notebook de An√°lisis:** Abrir y ejecutar todas las celdas de `notebooks/2_analisis_de_ventas.ipynb`. Las nuevas secciones al final del notebook demostrar√°n:
   - La ejecuci√≥n de las consultas de ranking y crecimiento mensual.
   - La llamada al procedimiento almacenado para generar un reporte de cliente din√°mico.
   - El uso impl√≠cito de la vista en las nuevas consultas.

---

## ‚úîÔ∏è Checklist de Requisitos (Fase 3)

| Requisito                               | Estado      | Verificaci√≥n                                          |
| --------------------------------------- | ----------- | ----------------------------------------------------- |
| Consultas con CTEs y Funciones Ventana  | ‚úÖ Cumplido | M√©todos en `repository.py` y resultados en notebook.  |
| Creaci√≥n de Vista                       | ‚úÖ Cumplido | `sql/3_advanced_objects.sql` y su uso en consultas.   |
| Creaci√≥n de Procedimiento Almacenado    | ‚úÖ Cumplido | `sql/3_advanced_objects.sql` y su uso desde Python.   |
| Integraci√≥n de todo desde Python        | ‚úÖ Cumplido | El notebook se ejecuta y llama a todos los m√©todos.   |
| Documentaci√≥n en Notebook               | ‚úÖ Cumplido | Celdas de Markdown explican cada paso del an√°lisis.   |
| Documentaci√≥n Final en `README.md`      | ‚úÖ Cumplido | Este mismo documento.                                 |
